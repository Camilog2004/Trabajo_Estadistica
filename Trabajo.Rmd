---
header-includes:
- \usepackage{longtable}
- \usepackage[utf8]{inputenc}
- \usepackage[spanish]{babel}\decimalpoint
- \setlength{\parindent}{0cm}
- \usepackage{amsmath}
- \usepackage{array}
- \usepackage{float}
- \usepackage{multirow}
output:
  pdf_document:
    number_sections: yes
  word_document: default
fontsize: 12pt
papersize: letter
geometry: margin = 1in
language: es
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, fig.align = "center", fig.pos = "H")
library(kableExtra)
library(knitr)
library(leaps)
source("Functions.R")
library(tidyverse)
```

```{=tex}
\input{titlepage}
\thispagestyle{empty}
\tableofcontents
\newpage
\thispagestyle{empty}
\listoffigures
\listoftables
\newpage
```

```{=tex}
\pagestyle{myheadings}
\setcounter{page}{3}
```
\section{Pregunta 1}
Se toma la base de datos 8, en la cual hay 5 variables regresoras, denominadas como:

$Y$: Riesgo de infección 

$X_1$: Duración de la estadía

$X_2$: Rutina de cultivos

$X_3$: Número de camas

$X_4$: Censo promedio diario

$X_5$: Número de enfermeras

A partir de ello se plantea el siguiente modelo incial:

$$
Y_i=\beta_0 + \beta_1 X_{1i} +\beta_2 X_{2i} + \beta_3 X_{3i} +\beta_4 X_{4i} + \beta_5 X_{5i} + \varepsilon_i; \ \varepsilon_i 
\stackrel{iid}{\sim}N(0,\sigma^2); \ 1 \leq i \leq 65
$$
```{r}
datos <- read.table("Equipo08.txt", header = T)
modelo <- lm(Y~.,data=datos)
betas <- round(coef(modelo),4)
betas1 <- as.data.frame(betas)
```

\subsection{Modelo de regresion}

Al realizar el ajuste al modelo con el fin de obtener la relacion de la variable respuesta con las variables regresoras obtenemos los siguientes coeficientes respectivamente:

```{r}
rownames(betas1) <- c("$\\beta_0$","$\\beta_1$","$\\beta_2$","$\\beta_3$","$\\beta_4$","$\\beta_5$")
betas1 %>% 
  kable(col.names = c("Valor del parametro"),caption="Valores coeficientes", escape = F, booktab = T, align = "c", row.names = T) %>% 
  kable_styling(latex_options = c("HOLD_position"))
```
La ecuacion de la regresion ajustada es:
$$
\hat{Y}_i=  `r betas[1]` + `r betas[2]` X_{1i} +`r betas[3]` X_{2i} + `r betas[4]` X_{3i} +`r betas[5]` X_{4i} + `r betas[6]`X_{5i}; \ 1 \leq i \leq 65 
$$
\subsection{Significancia de la regresión}
Se realizara un análisis de varianza para probar la significancia de los parametros, el cual se establece con el siguiente juego de hipotesis:
$$
\begin{cases}
  \begin{aligned}
    H_0&: \beta_1=\beta_2=\beta_3=\beta_4=\beta_5=0 \\
    H_a&: \text{Algún }\beta_j \text{ distinto de 0 para j=1, 2,..., 5}
  \end{aligned}
\end{cases}
$$
Cuyo estadístico de prueba es:

\begin{equation}
F_0 = \frac{MSR}{MSE} \stackrel{H_0}{\sim} f_{5, `r nrow(datos)-6`}\\
\end{equation}

Se hace la comparacion con la distribucion $f$ debido a que $F_0$ es un analisis de significancia globlal del modelo, o sea, que tanto cambia el modelo segun las variables regresoras, la distribucion $f$ es un analisis de varianza segun la cantidad de parametros y datos, si $f \leq F_0$ significa que el modelo tiene una varianza mayor, por lo que, tiene alguna relacion con al menos una de las variables regresoras.      

Ahora, se presenta la tabla Anova:
```{r}
tabla.anova <- myAnova(modelo)
rownames(tabla.anova) <- c("Regresión", "Error")
tabla.anova %>% 
  kable(col.names = c("Sumas de cuadrados", "Grados de libertad", "Cuadrado medio", "$F_0$", "P-valor"),caption = "Tabla  ANOVA para el modelo", escape=F, booktab=T, align = "c", row.names = T) %>% 
  kable_styling(latex_options = c("HOLD_position"))
```
De la tabla Anova, se observa un valor P casi igual a 0, lo  que permite rechazar la hipótesis nula en la que $\beta_j = 0$ con $1 \leq j \leq 5$, aceptando la hipótesis alternativa en la que algún $\beta_j \neq 0$, esto nos dice que hay al menos una relacion entre las variable respuesta y las regresoras permitiendonos asi concluir la significancia del modelo.

\subsection{Significancia  de los parámetros}
Antes se realizo una prueba general del modelo con el fin de saber si nos proporcionaba alguna informacion, ahora se realizara una prueba de hipotesis sobre los coeficientes individuales del modelo con el fin de saber cuales son significativos o no, se establece primero el juego de hipotesis:
$$
\begin{cases}
  \begin{aligned}
    H_0&: \beta_j=0 \\
    H_a&: \beta_j \neq 0 \ j=1, 2,..., 5
  \end{aligned}
\end{cases}
$$
El estadistico es el siguiente:

\begin{equation}
T_{j,0} = \frac{\hat{\beta}_j}{se(\hat{\beta}_j)} \stackrel{H_0}{\sim} t_{`r nrow(datos)-6`}\\
\end{equation}


En el siguiente cuadro se presenta información de los parámetros:


```{r}
tabla.coeficientes <- summary(modelo)$coefficients
rownames(tabla.coeficientes) <- paste("$\\beta_", 0:5, "$", sep = "")
tabla.coeficientes %>% 
  kable(col.names = c("$\\hat{\\beta_j}$", "$se(\\hat{\\beta_j})$", "$T_{0j}$", "P-valor"),caption = "Resumen de los coeficientes", escape=F, booktab=T, align = "c", row.names = T, digits = 4) %>% 
  kable_styling(latex_options = c("HOLD_position"))
```
Usando el criterio de rechazo del valor-P $\alpha > Val-P$ determinaremos que valores son significativos y cuales no, dado que no nos dan un valor especifico para $\alpha$ diremos que $\alpha = 0.05$ viendo la tabla solo hay dos valores significativos, o sea, que rechazamos su hipotesis nula que son $\beta_3$ y $\beta_5$ ya que sus P-valores son menores que $\alpha$, $\beta_0$ no hubiera sido interpretable en caso de que fuera significativa debido a que ninguna de las $X_{j,i}$ contiene al 0 en sus datos.

\subsection{Interpretación de los parámetros}

\textbf{$\hat{\beta_3}$:} Significa que por cada unidad que aumente $X_{3}$ la variable respuesta estimada $\hat{Y}_i$ aumenta en 0.0628 unidades cuando las demas variables se mantienen constantes, esto en otras palabras es que a medida que hayan mas camas mas aumenta la riesgo de infeccion.

\textbf{$\hat{\beta_5}$:} Significa que por cada unidad que aumente $X_{5}$ la variable respuesta estimada $\hat{Y}_i$ aumenta en 0.0024 unidades cuando las demas variables se mantienen constantes, aqui nos dice que segun el aumento de la cantidad de enfermeras aumenta el riesgo de infeccion.

\subsection{Coeficiente de determinación múltiple $R^2$}


El  modelo tiene un coeficiente de determinación múltiple $R^2 = 0.4947$, lo que significa que aproximadamente el $49.47\%$ de la variabilidad de $Y$ es explicada por el modelo de regresion ajustado debido a las variables independientes, el resto de la variabilidad es explicada por la variabilidad residual, o sea,$1-R^2$.

\newpage
\section{Pregunta 2}
\subsection{Planteamiento pruebas de hipótesis  y modelo reducido}

Según el Cuadro 3, las covariables que tienen el valor-P más alto en el modelo son $X_1, X_2, X_4$. 
Por medio de la tabla de todas las regresiones posibles se quiere hacer la siguiente prueba de hipótesis que permita concluir si el subconjunto de variables es significativo:


$$
\begin{cases}
\begin{aligned}
\text{H}_0&: \beta_1 =\beta_2 = \beta_4 = 0\\
\text{H}_1&: \text{Algún } \beta_j \text{ distinto de 0 para } j=1, 2, 4
\end{aligned}
\end{cases}
$$
```{r}
todas.regresiones <- myAllRegTable(modelo)
todas.regresiones <- todas.regresiones[c(31, 6), c(4, 6)]
row.names(todas.regresiones) <- c("Modelo  completo", "Modelo reducido")
todas.regresiones %>% 
    kable(col.names = c("Suma cuadratica de error", "Covariables en el modelo"), caption = "Resumen tabla de todas las regresiones posibles", escape=F, booktab=T, align = "c", row.names = T, digits = 4) %>% 
  kable_styling(latex_options = c("HOLD_position"))
```
Un modelo reducido para la prueba de significancia del subconjunto es:

$$Y_i = \beta_0 + \beta_3 X_{3i} + \beta_5 X_{5i} + \varepsilon; \ \varepsilon_i \stackrel{\text{iid}}{\sim} N(0, \sigma^2); \ 1 \leq i \leq 65$$
\subsection{Estadístico de prueba y conclusión}
Se construye el estadístico de prueba:

\begin{equation}
\begin{split}
F_0 &= \frac{(SSE(\beta_0, \beta_3, \beta_5) - SSE(\beta_0, \ \cdots, \ \beta_5))/3}{MSE(\beta_0, \ \cdots, \ \beta_5)} \stackrel{H_0}{\sim} f_{3, `r nrow(datos)-6`}\\
&= \frac{[69.028-58.420]/3}{0.990177} \\
&= 3.5711
\end{split}
\end{equation}

Si se compara el $F_0$ con $f_{0.95, 3, `r nrow(datos)-6`} = `r round(qf(0.95, 3, nrow(datos)-6), 4)`$, se puede ver que $F_0 > f_{0.95, 3, 59}$.

Usando $\alpha = 0.05$:

Como $F_0 > f_{0.95, 3, 59}$, entonces se rechaza $H_0$, por lo tanto, el subconjunto es significativo, en presencia de los demás parámetros.

Por lo anterior, llegamos a la conclusión que las variables no se pueden descartar del modelo porque el riesgo promedio de infección depende de al menos una de las variables presentes en el subconjunto.

\newpage
\section{Pregunta 3}
\subsection{Prueba de hipótesis y prueba de hipótesis matricial}
Queremos probar si: 
$$2\beta_1 = \beta_2; \ 5\beta_3  = \beta_4; \ \beta_4  = \beta_5 $$
Para esto tenemos la siguiente prueba de hipótesis:

$$
\begin{cases}
\begin{aligned}
\text{H}_0&: 2\beta_1 = \beta_2; \ 5\beta_3  = \beta_4; \ \beta_4  = \beta_5 \\
\text{H}_1&: 2\beta_1 \neq \beta_2  \ ó\ 5\beta_3 \neq \beta_4 \ ó\ \beta_4 \neq \beta_5
\end{aligned}
\end{cases}
$$
Podemos reescribirlas de la siguiente manera:

$$
\begin{cases}
\begin{aligned}
\text{H}_0&: 2\beta_1 - \beta_2 = 0; \ 5\beta_3  - \beta_4 = 0; \ \beta_4  - \beta_5 = 0 \\
\text{H}_1&: 2\beta_1 - \beta_2 \neq 0; \ 5\beta_3  - \beta_4 \neq 0; \ \beta_4  - \beta_5 \neq 0
\end{aligned}
\end{cases}
$$

Y ahora en términos matriciales:
$$
\begin{cases}
\begin{aligned}
\text{H}_0&: \mathbf{L} \underline{\mathbf{\beta}} = \underline{\mathbf{0}} \\
\text{H}_1&: \mathbf{L} \underline{\mathbf{\beta}} \neq \underline{\mathbf{0}} \\
\end{aligned}
\end{cases}
$$

Donde la matriz $\mathbf{L}$ está dada por:
$$
L = \begin{bmatrix}
  0 & 2 & -1 & 0 & 0 & 0\\
  0 & 0 & 0 & 5 & -1 & 0\\
  0 & 0 & 0 & 0 & 1 & -1
\end{bmatrix}
$$  
Para obtener el modelo reducido operamos:
$$Y_i = \beta_0  + \beta_1 X_{1i} + 2\beta_1 X_{2i} + \beta_3 X_{3i} + 5\beta_3 X_{4i} + 5\beta_3 X_{5i}+\varepsilon_i, \ \varepsilon_i \stackrel{\text{iid}}{\sim} N(0, \sigma^2); \ 1 \leq i \leq 65$$

Agrupando, el MR estará dado por: 
$$Y_i = \beta_0  + \beta_1 X^*_{1,2i}+ \beta_3 X^*_{3,4,5i} +\varepsilon_i, \ \varepsilon_i \stackrel{\text{iid}}{\sim} N(0, \sigma^2); \ 1 \leq i \leq 65$$

Donde $X^*_{1,2i} = X_{1i} + 2X_{2i}$ y $X^*_{3,4,5i} = X_{3i} + 5X_{4i}+ 5X_{5i}$

\subsection{Estadístico de prueba}

El estadístico de prueba $F_0$ es el siguiente:

\begin{equation}
F_0 = \frac{(SSE(MR) - SSE(MF))/3}{MSE(MF)} \stackrel{H_0}{\sim} f_{3, `r nrow(datos)-6`}\\
\end{equation}

Reemplazando el $SSE(MF)\ y \ el \ MSE(MF)$ conocidos:

\begin{equation}
F_0 = \frac{(SSE(MR) - 58.420)/3}{0.990177} \stackrel{H_0}{\sim} f_{3, `r nrow(datos)-6`}\\
\end{equation}

\newpage
\section{Pregunta 4}
\subsection{Supuestos del modelo}

\subsubsection{Normalidad de los residuales}

Para validar el supuesto de normalidad, se plante la prueba de hipótesis Shapiro-Wilk, seguida de un gráfico cuantil-cuantil:
$$
\begin{cases}
\begin{aligned}
  \text{H}_0&: \varepsilon_i \sim \text{Normal}\\
  \text{H}_1&: \varepsilon_i \nsim \text{Normal}
\end{aligned}
\end{cases}
$$
```{r fig.cap = "Gráfico cuantil-cuantil y normalidad de residuales"} 
myQQnorm(modelo, xlab = "Cuantiles teóricos",
         ylab = "Cuantiles muestrales", pch=20)
```

Analizando en un principio el valor-P de la prueba Shapiro-Wilk utilizando un nivel de significancia $\alpha = 0.05$, podemos observar que este valor-P es superior pues $0.9591 > 0.05$, por lo que no se cumple el criterio de rechazo, no rechazaríamos la hipótesis nula y se cumpliría el supuesto de normalidad. No obstante, en la gráfica de cuantiles...

\subsubsection{Varianza constante}

Para validar el supuesto de varianza constante analizaremos el gráfico de los residuales estudentizados vs los valores ajustados:

$$
\begin{cases}
\begin{aligned}
  \text{H}_0&: V[\varepsilon_i] = \sigma^2\\
  \text{H}_1&:  V[\varepsilon_i] \neq \sigma^2
\end{aligned}
\end{cases}
$$

```{r fig.cap = "Gráfico residuales estudentizados vs valores ajustados"}
res.stud <- round(rstandard(modelo), 4)
yhat <- round(modelo$fitted.values, 4)
plot(yhat, res.stud, xlab = "Valores Ajustados", 
     ylab = "Residuales Estudentizados", main = "Residuales Estudentizados vs Valores Ajustados", pch=20)
abline(h = 0, lty = 2, lwd = 2, col = 2)
```

Del análisis de la gráfica encontramos que el patrón de los puntos indica un aumento de la dispersión hasta poco antes del centro de la gráfica y después hay un decrecimiento de la dispersión. En base a esto podemos concluir que el supuesto de varianza constante no se cumple. Es posible que algunas observaciones extremas estén afectando nuestro análisis.

\subsection{Verificación de las observaciones}

```{r}
Cooks.D <- round(cooks.distance(modelo), 4)
hii.value <- round(hatvalues(modelo), 4)
Dffits <- round(dffits(modelo), 4)
base.diagnostico <- data.frame(res.stud, Cooks.D, hii.value, Dffits)
```

\subsubsection{Datos atípicos}

```{r fig.cap = "Identificación de datos atípicos"}
with(base.diagnostico,
     plot(res.stud, xlab="Observación", ylab = "Residuales",
          main = "Residuales estudentizados", pch = 20, ylim=c(-5, 5)))
abline(h = 3, col="red", lty = "dashed")
abline(h =- 3, col="red", lty = "dashed")
```

```{r include = F}
atipicos.criterio <- 3
base.diagnostico[base.diagnostico$res.stud > atipicos.criterio | base.diagnostico$res.stud < -atipicos.criterio, ]
```
Tal como nos los muestra la gráfica anterior, no se observa ningún dato atípico en el conjunto de datos que tenemos, esto porque ningún residual estudentizado sobrepasa el criterio correspondiente $|r_{estudentizados}| > 3$.

\subsubsection{Puntos de balanceo}

```{r fig.cap = "Identificación de puntos de balanceo"}
hii.criterio <- 2*(6/(nrow(datos)))
with(base.diagnostico,
     plot(hii.value, xlab="Observación", ylab = "Valor hii",
          main = "Gráfica de hii para las observaciones", pch = 20, ylim=c(-0.3, 0.5)))
abline(h = hii.criterio, col="red", lty = "dashed")
```
```{r include = F}
base.diagnostico[base.diagnostico$hii.value > hii.criterio, ]
```

Analizando la gráfica, concluimos que tenemos 5 puntos de balanceo (los dos que están exactamente en la linea son menores al valor $h_{ii} = 2\frac{p}{n}= 2\frac{6}{65} =0.1846$ que representa la linea punteada roja). Las 5 observaciones 1,24,28,34 y 38 ,como se muestra en la tabla, cumplen con el criterio correspondiente $h_{ii} > 2\frac{p}{n}$

\subsubsection{Puntos  influenciales}

```{r fig.cap="Criterio distancias de Cook para puntos influenciales"}
criterio.cook <- 1
with(base.diagnostico,
     plot(Cooks.D, xlab="Observación", ylab = "Distancia de Cook",
          main = "Gráfica de distancias de Cook", pch = 20, ylim=c(-1.5, 1.5)))
abline(h = criterio.cook, col="red", lty = "dashed")
#base.diagnostico[base.diagnostico$Cooks.D > criterio.cook, ]
```

Con el criterio Cook que nos indica que para que sea un punto influencial $D_{i} > 1$, observamos que ningun punto cumple, tal cual como se ve en la gráfica ya que ninguno sobrepasa la linea roja punteada.

```{r fig.cap="Criterio Dffits para puntos influenciales"}
Dffits.criterio <- 2* (6/nrow(datos))^(1/2)
with(base.diagnostico,
     plot(Dffits, xlab="Observación", ylab = "Dffit",
          main = "Gráfica de observaciones vs Dffits", pch = 20, ylim=c(-1.5, 1.5)))
abline(h = Dffits.criterio, col="red", lty = "dashed")
abline(h = -Dffits.criterio, col="red", lty = "dashed")

tabla <- base.diagnostico[base.diagnostico$Dffits > Dffits.criterio | base.diagnostico$Dffits < -Dffits.criterio, ]

rownames(tabla) <- c("10","18","38")
tabla %>% 
  kable(col.names = c("Residuales estudentizados", "Distancia Cook", "Valores $h_{ii}$", "Dffits"),caption = "Puntos influenciales", escape=F, booktab=T, align = "c", row.names = T, digits = 4) %>% 
  kable_styling(latex_options = c("HOLD_position"))

```

Tal como nos lo muestra la gráfica y la tabla, tenemos 3 puntos influenciales que cumplen el criterio del diágnostico DFFITS el cual establece que es un punto influencial si $|D_{ffit}| > 2\sqrt{\frac{p}{n}}$, para este conjunto de datos en particular $|D_{ffit}| > 2\sqrt{\frac{6}{56}}= 0.6076$.

\subsection{Conclusión}